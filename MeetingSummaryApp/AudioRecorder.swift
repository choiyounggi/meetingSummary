//
//  AudioRecorder.swift
//  MeetingSummaryApp
//
//  Created by ìµœì˜ê¸° on 11/23/25.
//

import Foundation
import AVFoundation
import Combine
import CoreGraphics
import SwiftUI
#if os(macOS)
import AppKit
#endif

class AudioRecorder: NSObject, ObservableObject, AVAudioPlayerDelegate {

    // MARK: - Recording ìƒíƒœ
    @Published var isRecording: Bool = false
    @Published var currentLevel: CGFloat = 0.0      // íŒŒë™ 0.0 ~ 1.0
    @Published var isUploading: Bool = false
    @Published var summaryURL: URL?
    @Published var errorMessage: String?

    // MARK: - Playback ìƒíƒœ
    @Published var hasRecording: Bool = false       // ë…¹ìŒ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€
    @Published var isPlaying: Bool = false
    @Published var playbackDuration: Double = 0.0   // ì „ì²´ ê¸¸ì´ (ì´ˆ)
    @Published var playbackCurrentTime: Double = 0.0 // í˜„ì¬ ì¬ìƒ ìœ„ì¹˜ (ì´ˆ)

    // MARK: - ë‚´ë¶€ í•„ë“œ
    private var audioRecorder: AVAudioRecorder?
    private var audioPlayer: AVAudioPlayer?
    private var meterTimer: Timer?
    private var playbackTimer: Timer?
    private var recordedFileURL: URL?
    
    // MARK: - OpenAI ì„¤ì •
    private let openAIAPIKey: String = "openAI KEYê°’ ì¶”ê°€ í•„ìš”"

    // MARK: - Public API (ë…¹ìŒ)

    func startRecording() {
        // 1) ë¨¼ì € ë§ˆì´í¬ ê¶Œí•œ ì²´í¬
        checkMicPermission { [weak self] granted in
            guard let self = self, granted else { return }

            // 2) ê¶Œí•œì´ í—ˆìš©ëœ ê²½ìš°ì—ë§Œ ì‹¤ì œ ë…¹ìŒ ì‹œì‘ ë¡œì§ ìˆ˜í–‰
            // ì—…ë¡œë“œ/ì¬ìƒ ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
            self.summaryURL = nil
            self.errorMessage = nil
            self.stopPlaybackIfNeeded()
            self.hasRecording = false
            self.playbackDuration = 0
            self.playbackCurrentTime = 0

            let fileName = "meeting-\(UUID().uuidString).m4a"
            let tempDir = FileManager.default.temporaryDirectory
            let fileURL = tempDir.appendingPathComponent(fileName)
            self.recordedFileURL = fileURL

            let settings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
                AVSampleRateKey: 44100,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]

            do {
                self.audioRecorder = try AVAudioRecorder(url: fileURL, settings: settings)
                self.audioRecorder?.isMeteringEnabled = true
                self.audioRecorder?.prepareToRecord()
                self.audioRecorder?.record()

                self.isRecording = true
                self.startMetering()
            } catch {
                self.errorMessage = "ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: \(error.localizedDescription)"
                self.isRecording = false
            }
        }
    }

    func stopRecording() {
        guard isRecording else { return }

        audioRecorder?.stop()
        audioRecorder = nil
        isRecording = false

        stopMetering()
        currentLevel = 0.0

        guard let fileURL = recordedFileURL else {
            errorMessage = "ë…¹ìŒ íŒŒì¼ URLì´ ì—†ìŠµë‹ˆë‹¤."
            return
        }

        // ë…¹ìŒ íŒŒì¼ í¬ê¸°/ì¡´ì¬ í™•ì¸
        let path = fileURL.path
        do {
            let attrs = try FileManager.default.attributesOfItem(atPath: path)
            let fileSize = (attrs[.size] as? NSNumber)?.intValue ?? 0
            print("ğŸ™ Recorded file: \(path), size: \(fileSize) bytes")

            if fileSize == 0 {
                DispatchQueue.main.async {
                    self.errorMessage = "ë…¹ìŒ íŒŒì¼ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤. ì‹¤ì œ ë…¹ìŒì´ ì•ˆ ë˜ì—ˆì„ ìˆ˜ ìˆì–´ìš”."
                }
            }
        } catch {
            print("âš ï¸ Failed to read file attributes: \(error)")
            DispatchQueue.main.async {
                self.errorMessage = "ë…¹ìŒ íŒŒì¼ ì •ë³´ë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: \(error.localizedDescription)"
            }
        }

        // âœ… ì¬ìƒìš© ì¤€ë¹„
        preparePlayback(fileURL: fileURL)

        // âœ… ì—…ë¡œë“œ
        uploadAudio(fileURL: fileURL)
    }

    // MARK: - Metering (íŒŒë™ìš©)

    private func startMetering() {
        meterTimer = Timer.scheduledTimer(withTimeInterval: 0.05, repeats: true) { [weak self] _ in
            self?.updateMeter()
        }
    }

    private func stopMetering() {
        meterTimer?.invalidate()
        meterTimer = nil
    }

    private func updateMeter() {
        guard let recorder = audioRecorder, recorder.isRecording else { return }

        recorder.updateMeters()
        let dB = recorder.averagePower(forChannel: 0)
        let minDb: Float = -60.0
        let level: CGFloat

        if dB < minDb {
            level = 0.0
        } else {
            let normalized = (dB - minDb) / -minDb
            level = CGFloat(normalized)
        }

        DispatchQueue.main.async {
            withAnimation(.linear(duration: 0.05)) {
                self.currentLevel = level
            }
        }
    }

    // MARK: - Playback ì¤€ë¹„/ì œì–´

    private func preparePlayback(fileURL: URL) {
        do {
            let player = try AVAudioPlayer(contentsOf: fileURL)
            player.delegate = self
            player.prepareToPlay()

            // âœ… ë³¼ë¥¨ ìµœëŒ€ë¡œ (0.0~1.0)
            player.volume = 1.0

            audioPlayer = player

            DispatchQueue.main.async {
                self.playbackDuration = player.duration
                self.playbackCurrentTime = 0
                self.hasRecording = true
                self.isPlaying = false
            }
        } catch {
            DispatchQueue.main.async {
                self.errorMessage = "ì¬ìƒ ì¤€ë¹„ ì‹¤íŒ¨: \(error.localizedDescription)"
            }
        }
    }

    func play() {
        guard let player = audioPlayer, hasRecording else { return }
        if !player.isPlaying {
            player.play()
            isPlaying = true
            startPlaybackTimer()
        }
    }

    func pause() {
        guard let player = audioPlayer else { return }
        if player.isPlaying {
            player.pause()
            isPlaying = false
            stopPlaybackTimer()
        }
    }

    func seek(to time: Double) {
        guard let player = audioPlayer, hasRecording else { return }
        let clamped = max(0, min(time, player.duration))
        player.currentTime = clamped
        playbackCurrentTime = clamped
    }

    private func startPlaybackTimer() {
        stopPlaybackTimer()
        playbackTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            guard let self = self, let player = self.audioPlayer else { return }
            DispatchQueue.main.async {
                self.playbackCurrentTime = player.currentTime
                if !player.isPlaying {
                    self.isPlaying = false
                    self.stopPlaybackTimer()
                }
            }
        }
    }

    private func stopPlaybackTimer() {
        playbackTimer?.invalidate()
        playbackTimer = nil
    }

    private func stopPlaybackIfNeeded() {
        audioPlayer?.stop()
        isPlaying = false
        stopPlaybackTimer()
        playbackCurrentTime = 0
    }

    // MARK: - AVAudioPlayerDelegate

    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        DispatchQueue.main.async {
            self.isPlaying = false
            self.playbackCurrentTime = self.playbackDuration
        }
        stopPlaybackTimer()
    }

    // MARK: - ê¶Œí•œ ì²´í¬

    private func checkMicPermission(completion: @escaping (Bool) -> Void) {
        let status = AVCaptureDevice.authorizationStatus(for: .audio)

        switch status {
        case .authorized:
            // ì´ë¯¸ í—ˆìš©
            completion(true)

        case .notDetermined:
            // ì²˜ìŒ ìš”ì²­ â†’ ì‹œìŠ¤í…œ ê¶Œí•œ íŒì—…
            AVCaptureDevice.requestAccess(for: .audio) { granted in
                DispatchQueue.main.async {
                    if !granted {
#if os(macOS)
                        self.errorMessage = "ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì„¤ì • > ê°œì¸ì •ë³´ ë³´í˜¸ ë° ë³´ì•ˆ > ë§ˆì´í¬ì—ì„œ ì´ ì•±ì„ í—ˆìš©í•´ì£¼ì„¸ìš”. í•„ìš” ì‹œ ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì„¤ì •ì„ ì—¬ì„¸ìš”."
#else
                        self.errorMessage = "ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¤ì • > ê°œì¸ì •ë³´ ë³´í˜¸ ë° ë³´ì•ˆ > ë§ˆì´í¬ì—ì„œ ì´ ì•±ì„ í—ˆìš©í•´ì£¼ì„¸ìš”."
#endif
                    }
                    completion(granted)
                }
            }

        case .denied, .restricted:
            // ì´ì „ì— ê±°ë¶€í–ˆê±°ë‚˜ ì œí•œëœ ìƒíƒœ
            DispatchQueue.main.async {
#if os(macOS)
                self.errorMessage = "ë§ˆì´í¬ ê¶Œí•œì´ êº¼ì ¸ ìˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì„¤ì • > ê°œì¸ì •ë³´ ë³´í˜¸ ë° ë³´ì•ˆ > ë§ˆì´í¬ì—ì„œ ì´ ì•±ì„ í—ˆìš©í•´ì£¼ì„¸ìš”. í•„ìš” ì‹œ ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì„¤ì •ì„ ì—¬ì„¸ìš”."
#else
                self.errorMessage = "ë§ˆì´í¬ ê¶Œí•œì´ êº¼ì ¸ ìˆìŠµë‹ˆë‹¤. ì„¤ì • > ê°œì¸ì •ë³´ ë³´í˜¸ ë° ë³´ì•ˆ > ë§ˆì´í¬ì—ì„œ ì´ ì•±ì„ í—ˆìš©í•´ì£¼ì„¸ìš”."
#endif
            }
            completion(false)

        @unknown default:
            completion(false)
        }
    }
    
    #if os(macOS)
    @MainActor
    func openMicPrivacySettings() {
        // Try to open the Privacy Microphone pane directly
        if let url = URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_Microphone") {
            NSWorkspace.shared.open(url)
        } else if let url = URL(string: "x-apple.systempreferences:com.apple.preference.security") {
            NSWorkspace.shared.open(url)
        }
    }
    #endif
    
    //  AudioRecorder.swift ë‚´, class AudioRecorder { ... } ì•ˆìª½ì— ì¶”ê°€
    //
    // MARK: - Public API (ì™¸ë¶€ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬)
    /// ë“œë˜ê·¸&ë“œë¡­ ë“±ìœ¼ë¡œ ë°›ì€ ì™¸ë¶€ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°”ë¡œ STT/ìš”ì•½ í”Œë¡œìš°ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    func processExternalFile(url: URL) {
        // ê¸°ì¡´ ì¬ìƒ ì¤‘ì§€
        audioPlayer?.stop()
        isPlaying = false

        // ë“œë¡­ëœ íŒŒì¼ì„ í˜„ì¬ ë…¹ìŒ íŒŒì¼ë¡œ ì·¨ê¸‰
        recordedFileURL = url

        // ì¬ìƒ ì¤€ë¹„ (ì¬ìƒ ì»¨íŠ¸ë¡¤ì—ì„œ ê¸¸ì´ í‘œì‹œìš©)
        do {
            let player = try AVAudioPlayer(contentsOf: url)
            audioPlayer = player
            audioPlayer?.delegate = self
            playbackDuration = player.duration
            playbackCurrentTime = 0
            hasRecording = true
        } catch {
            DispatchQueue.main.async {
                self.errorMessage = "ì™¸ë¶€ íŒŒì¼ ì¬ìƒ ì¤€ë¹„ ì‹¤íŒ¨: \(error.localizedDescription)"
            }
        }

        // ë°”ë¡œ ì—…ë¡œë“œ(STT â†’ n8n) ì‹œì‘
        uploadAudio(fileURL: url)
    }
    
    // MARK: - ì—…ë¡œë“œ

    private func uploadAudio(fileURL: URL) {
        isUploading = true
        errorMessage = nil
        
        let path = fileURL.path
        var fileSize: Int64 = 0
        do {
            let attrs = try FileManager.default.attributesOfItem(atPath: path)
            fileSize = (attrs[.size] as? NSNumber)?.int64Value ?? 0
            print("â¬†ï¸ Transcribe & upload file path: \(path), size: \(fileSize) bytes")
        } catch {
            print("âš ï¸ Failed to read file attributes for upload: \(error)")
        }
        
        // Whisper ë‹¨ì¼ ìš”ì²­ìœ¼ë¡œ ë³´ë‚¼ ìµœëŒ€ íŒŒì¼ í¬ê¸°(ì˜ˆ: 20MB)
        let maxSingleSize: Int64 = 20 * 1024 * 1024
        
        if fileSize > 0 && fileSize > maxSingleSize {
            // ëŒ€ìš©ëŸ‰ íŒŒì¼ â†’ ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ìˆœì°¨ STT í›„ í…ìŠ¤íŠ¸ë¥¼ ì´ì–´ë¶™ì„
            print("ğŸ”ª Large audio detected (\(fileSize) bytes), using chunked STT")
            transcribeLargeAudio(fileURL: fileURL) { [weak self] result in
                guard let self = self else { return }
                
                switch result {
                case .failure(let error):
                    DispatchQueue.main.async {
                        self.isUploading = false
                        self.errorMessage = "STT ì‹¤íŒ¨(ëŒ€ìš©ëŸ‰): \(error.localizedDescription)"
                    }
                case .success(let transcript):
                    print("ğŸ“ STT transcript (chunked) length: \(transcript.count) chars")
                    // ì„±ê³µ ì‹œì—ëŠ” isUploading í”Œë˜ê·¸ë¥¼ n8n ì—…ë¡œë“œê°€ ëë‚  ë•Œê¹Œì§€ ìœ ì§€
                    self.sendTranscriptToN8N(transcript: transcript)
                }
            }
        } else {
            // ì†Œìš©ëŸ‰ íŒŒì¼ â†’ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í•œ ë²ˆì— STT í˜¸ì¶œ
            let audioData: Data
            do {
                audioData = try Data(contentsOf: fileURL)
            } catch {
                DispatchQueue.main.async {
                    self.isUploading = false
                    self.errorMessage = "ë…¹ìŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: \(error.localizedDescription)"
                }
                return
            }
            
            let fileName = fileURL.lastPathComponent
            
            transcribeWithOpenAI(audioData: audioData, fileName: fileName) { [weak self] result in
                guard let self = self else { return }
                
                switch result {
                case .failure(let error):
                    DispatchQueue.main.async {
                        self.isUploading = false
                        self.errorMessage = "STT ì‹¤íŒ¨: \(error.localizedDescription)"
                    }
                case .success(let transcript):
                    print("ğŸ“ STT transcript length: \(transcript.count) chars")
                    // ì„±ê³µ ì‹œì—ëŠ” isUploading í”Œë˜ê·¸ë¥¼ n8n ì—…ë¡œë“œê°€ ëë‚  ë•Œê¹Œì§€ ìœ ì§€
                    self.sendTranscriptToN8N(transcript: transcript)
                }
            }
        }
    }
    
    // MARK: - OpenAI Whisper STT í˜¸ì¶œ
    
    private struct OpenAITranscriptionResponse: Decodable {
        let text: String
    }
    
    /// OpenAI Whisper Audio Transcriptions APIë¥¼ í˜¸ì¶œí•´ STT í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    private func transcribeWithOpenAI(audioData: Data, fileName: String, completion: @escaping (Result<String, Error>) -> Void) {
        guard let url = URL(string: "https://api.openai.com/v1/audio/transcriptions") else {
            completion(.failure(NSError(domain: "AudioRecorder", code: -1, userInfo: [NSLocalizedDescriptionKey: "ì˜ëª»ëœ OpenAI STT URL"])))
            return
        }
        
        let boundary = "Boundary-\(UUID().uuidString)"
        let lineBreak = "\r\n"
        
        // 15ë¶„ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        let config = URLSessionConfiguration.default
        config.timeoutIntervalForRequest = 900      // 15ë¶„
        config.timeoutIntervalForResource = 900     // 15ë¶„
        let session = URLSession(configuration: config)
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(openAIAPIKey)", forHTTPHeaderField: "Authorization")
        request.timeoutInterval = 900               // ìš”ì²­ ìì²´ì—ë„ 15ë¶„ íƒ€ì„ì•„ì›ƒ
        
        var body = Data()
        
        // model í•„ë“œ
        body.append("--\(boundary)\(lineBreak)".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"model\"\(lineBreak)\(lineBreak)".data(using: .utf8)!)
        body.append("whisper-1\(lineBreak)".data(using: .utf8)!)
        
        // (ì„ íƒ) ì–¸ì–´ ëª…ì‹œ - í•œêµ­ì–´ ê¸°ì¤€
        body.append("--\(boundary)\(lineBreak)".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"language\"\(lineBreak)\(lineBreak)".data(using: .utf8)!)
        body.append("ko\(lineBreak)".data(using: .utf8)!)
        
        // file í•„ë“œ
        body.append("--\(boundary)\(lineBreak)".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"file\"; filename=\"\(fileName)\"\(lineBreak)".data(using: .utf8)!)
        body.append("Content-Type: audio/m4a\(lineBreak)\(lineBreak)".data(using: .utf8)!)
        body.append(audioData)
        body.append(lineBreak.data(using: .utf8)!)
        
        // ë
        body.append("--\(boundary)--\(lineBreak)".data(using: .utf8)!)
        
        let task = session.uploadTask(with: request, from: body) { data, response, error in
            if let error = error {
                completion(.failure(error))
                return
            }
            
            guard let httpResponse = response as? HTTPURLResponse else {
                completion(.failure(NSError(domain: "AudioRecorder", code: -2, userInfo: [NSLocalizedDescriptionKey: "ì˜ëª»ëœ OpenAI ì‘ë‹µ í˜•ì‹"])))
                return
            }
            
            guard (200..<300).contains(httpResponse.statusCode) else {
                let msg = "OpenAI STT ì‘ë‹µ ì½”ë“œ: \(httpResponse.statusCode)"
                completion(.failure(NSError(domain: "AudioRecorder", code: httpResponse.statusCode, userInfo: [NSLocalizedDescriptionKey: msg])))
                return
            }
            
            guard let data = data else {
                completion(.failure(NSError(domain: "AudioRecorder", code: -3, userInfo: [NSLocalizedDescriptionKey: "OpenAI STT ì‘ë‹µ ë°ì´í„° ì—†ìŒ"])))
                return
            }
            
            if let debugText = String(data: data, encoding: .utf8) {
                print("ğŸ“© OpenAI STT raw response:\n\(debugText)")
            }
            
            do {
                let decoded = try JSONDecoder().decode(OpenAITranscriptionResponse.self, from: data)
                completion(.success(decoded.text))
            } catch {
                completion(.failure(error))
            }
        }
        
        task.resume()
    }
    
    // n8n ì‘ë‹µ íŒŒì‹±ìš© êµ¬ì¡°ì²´ (ìš”ì•½ ê²°ê³¼ URL í¬í•¨)
    private struct N8NSummaryResponse: Decodable {
        let summaryUrl: String?
        let url: String?
    }
    
    // MARK: - n8n ì›Œí¬í”Œë¡œìš° í˜¸ì¶œ (STT í…ìŠ¤íŠ¸ ì „ë‹¬)
    
    private func sendTranscriptToN8N(transcript: String) {
        guard let url = URL(string: "https://www.linkly.kr/n8n/webhook/098e8967-d9fc-4cbc-affa-92efff9fcff9") else {
            DispatchQueue.main.async {
                self.isUploading = false
                self.errorMessage = "ì˜ëª»ëœ n8n API URL"
            }
            return
        }
        
        // 15ë¶„ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        let config = URLSessionConfiguration.default
        config.timeoutIntervalForRequest = 900      // 15ë¶„
        config.timeoutIntervalForResource = 900     // 15ë¶„
        let session = URLSession(configuration: config)
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.timeoutInterval = 900               // ìš”ì²­ ìì²´ì—ë„ 15ë¶„ íƒ€ì„ì•„ì›ƒ
        
        // n8n ìª½ì—ì„œ transcript í•„ë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬í•˜ë„ë¡ ê°€ì •
        let payload: [String: Any] = [
            "transcript": transcript
        ]
        
        do {
            let data = try JSONSerialization.data(withJSONObject: payload, options: [])
            request.httpBody = data
        } catch {
            DispatchQueue.main.async {
                self.isUploading = false
                self.errorMessage = "ìš”ì²­ JSON ìƒì„± ì‹¤íŒ¨: \(error.localizedDescription)"
            }
            return
        }
        
        let task = session.dataTask(with: request) { [weak self] data, response, error in
            guard let self = self else { return }
            
            if let error = error as NSError? {
                print("âŒ n8n upload error: \(error.domain) \(error.code) \(error.localizedDescription)")
                DispatchQueue.main.async {
                    self.isUploading = false
                    self.errorMessage = "ì—…ë¡œë“œ ì‹¤íŒ¨: \(error.localizedDescription) (code: \(error.code))"
                }
                return
            }
            
            guard let httpResponse = response as? HTTPURLResponse else {
                DispatchQueue.main.async {
                    self.isUploading = false
                    self.errorMessage = "ì˜ëª»ëœ n8n ì‘ë‹µ í˜•ì‹"
                }
                return
            }
            
            print("ğŸ“¡ n8n HTTP status code: \(httpResponse.statusCode)")
            print("ğŸ“¡ n8n Response headers: \(httpResponse.allHeaderFields)")
            
            guard (200..<300).contains(httpResponse.statusCode) else {
                DispatchQueue.main.async {
                    self.isUploading = false
                    self.errorMessage = "ì„œë²„ ì‘ë‹µ ì½”ë“œ: \(httpResponse.statusCode)"
                }
                return
            }
            
            // ì‘ë‹µ ë°”ë”” ë””ë²„ê·¸ìš© ì¶œë ¥ ë° URL íŒŒì‹±
            var parsedSummaryURL: URL?
            if let data = data {
                if let text = String(data: data, encoding: .utf8) {
                    print("ğŸ“© n8n raw response body:\n\(text)")
                } else {
                    print("ğŸ“© n8n raw response body length: \(data.count) bytes")
                }
                
                // n8n ì‘ë‹µ JSONì—ì„œ summaryUrl ë˜ëŠ” url í•„ë“œ íŒŒì‹±
                do {
                    let decoded = try JSONDecoder().decode(N8NSummaryResponse.self, from: data)
                    if let urlString = decoded.summaryUrl ?? decoded.url,
                       let url = URL(string: urlString) {
                        parsedSummaryURL = url
                    }
                } catch {
                    print("âš ï¸ n8n ì‘ë‹µ JSON ë””ì½”ë”© ì‹¤íŒ¨: \(error.localizedDescription)")
                }
            }
            
            DispatchQueue.main.async {
                self.isUploading = false
                // n8nì´ ë°˜í™˜í•œ URLì´ ìˆë‹¤ë©´ ìš”ì•½ ê²°ê³¼ URLë¡œ ë°˜ì˜
                if let url = parsedSummaryURL {
                    self.summaryURL = url
                }
            }
        }
        
        task.resume()
    }
    /// ëŒ€ìš©ëŸ‰ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì¼ì • ê¸¸ì´(ì˜ˆ: 10ë¶„) ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ìˆœì°¨ì ìœ¼ë¡œ STT ìˆ˜í–‰ í›„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤.
    private func transcribeLargeAudio(fileURL: URL, completion: @escaping (Result<String, Error>) -> Void) {
        let asset = AVURLAsset(url: fileURL)
        let durationSeconds = CMTimeGetSeconds(asset.duration)
        
        guard durationSeconds.isFinite && durationSeconds > 0 else {
            completion(.failure(NSError(domain: "AudioRecorder",
                                        code: -20,
                                        userInfo: [NSLocalizedDescriptionKey: "ì˜¤ë””ì˜¤ duration ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."])))
            return
        }
        
        // ì²­í¬ ê¸¸ì´(ì´ˆ) - 10ë¶„ ë‹¨ìœ„
        let chunkDuration: Double = 600.0
        let chunkCount = max(1, Int(ceil(durationSeconds / chunkDuration)))
        
        print("ğŸ”ª Splitting audio into \(chunkCount) chunks (duration: \(durationSeconds) seconds)")
        
        var transcripts: [String] = Array(repeating: "", count: chunkCount)
        var currentIndex = 0
        
        func processNextChunk() {
            if currentIndex >= chunkCount {
                // ëª¨ë“  ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ â†’ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
                let merged = transcripts.joined(separator: " ")
                completion(.success(merged))
                return
            }
            
            let startTime = Double(currentIndex) * chunkDuration
            let remaining = durationSeconds - startTime
            let thisDuration = min(chunkDuration, remaining)
            
            print("ğŸ”ª Exporting chunk \(currentIndex + 1)/\(chunkCount) [start=\(startTime), duration=\(thisDuration)]")
            
            exportAudioChunk(asset: asset, startTime: startTime, duration: thisDuration) { [weak self] exportResult in
                guard let self = self else { return }
                
                switch exportResult {
                case .failure(let error):
                    completion(.failure(error))
                case .success(let chunkURL):
                    do {
                        let chunkData = try Data(contentsOf: chunkURL)
                        let chunkFileName = "chunk-\(currentIndex)-\(fileURL.lastPathComponent)"
                        
                        self.transcribeWithOpenAI(audioData: chunkData, fileName: chunkFileName) { sttResult in
                            // ì‚¬ìš© ì™„ë£Œ í›„ ì²­í¬ íŒŒì¼ì€ ì‚­ì œ ì‹œë„
                            try? FileManager.default.removeItem(at: chunkURL)
                            
                            switch sttResult {
                            case .failure(let error):
                                completion(.failure(error))
                            case .success(let text):
                                transcripts[currentIndex] = text
                                currentIndex += 1
                                processNextChunk()
                            }
                        }
                    } catch {
                        completion(.failure(error))
                    }
                }
            }
        }
        
        processNextChunk()
    }

    /// AVAssetì—ì„œ ì§€ì •í•œ êµ¬ê°„(startTime, duration)ì„ m4a íŒŒì¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.
    private func exportAudioChunk(asset: AVAsset,
                                  startTime: Double,
                                  duration: Double,
                                  completion: @escaping (Result<URL, Error>) -> Void) {
        guard let exportSession = AVAssetExportSession(asset: asset, presetName: AVAssetExportPresetAppleM4A) else {
            completion(.failure(NSError(domain: "AudioRecorder",
                                        code: -21,
                                        userInfo: [NSLocalizedDescriptionKey: "AVAssetExportSession ìƒì„± ì‹¤íŒ¨"])))
            return
        }
        
        let outputURL = FileManager.default.temporaryDirectory
            .appendingPathComponent("chunk-\(UUID().uuidString).m4a")
        
        exportSession.outputURL = outputURL
        exportSession.outputFileType = .m4a
        
        let timescale = asset.duration.timescale
        let start = CMTime(seconds: startTime, preferredTimescale: timescale)
        let dur = CMTime(seconds: duration, preferredTimescale: timescale)
        exportSession.timeRange = CMTimeRange(start: start, duration: dur)
        
        exportSession.exportAsynchronously {
            switch exportSession.status {
            case .completed:
                completion(.success(outputURL))
            case .failed, .cancelled:
                let error = exportSession.error ?? NSError(domain: "AudioRecorder",
                                                           code: -22,
                                                           userInfo: [NSLocalizedDescriptionKey: "ì˜¤ë””ì˜¤ ì²­í¬ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨"])
                completion(.failure(error))
            default:
                break
            }
        }
    }
}
